{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61079390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructField, StructType, IntegerType,\n",
    "    StringType, DateType, DecimalType\n",
    ")\n",
    "\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b73e8",
   "metadata": {},
   "source": [
    "# Setting log level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3305467",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedda32e",
   "metadata": {},
   "source": [
    "# Create parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c19f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.text('storage_account', '0')\n",
    "dbutils.widgets.text('year', '0')\n",
    "dbutils.widgets.text('month', '0')\n",
    "dbutils.widgets.text('day', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account = dbutils.widgets.get('storage_account')\n",
    "year = dbutils.widgets.get('year')\n",
    "month = dbutils.widgets.get('month')\n",
    "day = dbutils.widgets.get('day')\n",
    "\n",
    "bronze_file_path = f'abfss://bronze@{storage_account}.dfs.core.windows.net/raw_data/{year}/{month}/{day}/'\n",
    "checks_file_path = '/pipeline_project/check/checks_silver.yml'\n",
    "silver_storage_path = f'abfss://silver@{storage_account}.dfs.core.windows.net/transformed_data/{year}/{month}/{day}/'\n",
    "\n",
    "# create data quality instance connected to databricks workspace\n",
    "dq_engine = DQEngine(WorkspaceClient())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623e8b0",
   "metadata": {},
   "source": [
    "# Define schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_schema = StructType([\n",
    "    StructField('Sales_Person_ID', IntegerType(), True),\n",
    "    StructField('Sales_Person', StringType(), True),\n",
    "    StructField('Country', StringType(), True),\n",
    "    StructField('Product_ID', IntegerType(), True),\n",
    "    StructField('Product', StringType(), True),\n",
    "    StructField('Date', DateType(), True),\n",
    "    StructField('Amount', StringType(), True),\n",
    "    StructField('Boxes_Shipped', IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020557a",
   "metadata": {},
   "source": [
    "# Run common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47acfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./utils/common_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2a7c3",
   "metadata": {},
   "source": [
    "# Define extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c47dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_bronze: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Clean data before adding new columns.\n",
    "\n",
    "    Parameter:\n",
    "        df_bronze: Dataframe containing bronze data.\n",
    "\n",
    "    Return:\n",
    "        Cleaned dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # drop null and duplicate\n",
    "    df_cleaned = df_bronze.dropna() \\\n",
    "        .dropDuplicates(['Sales_Person_ID', 'Country', 'Product_ID', 'Date', 'Boxes_Shipped'])\n",
    "\n",
    "    # change country name\n",
    "    df_cleaned = df_cleaned.withColumn(\n",
    "            'Country',\n",
    "            F.when(\n",
    "                F.col('Country') == 'UK',\n",
    "                'United Kingdom'\n",
    "            ).when(\n",
    "                F.col('Country') == 'USA',\n",
    "                'United States'\n",
    "            ).otherwise(F.col('Country'))\n",
    "        )\n",
    "    \n",
    "    # remove whitespace\n",
    "    df_cleaned = df_cleaned.withColumn('Sales_Person', F.trim('Sales_Person')) \\\n",
    "            .withColumn('Country', F.trim('Country')) \\\n",
    "            .withColumn('Product', F.trim('Product')) \\\n",
    "            .withColumn('Amount', F.trim('Amount'))\n",
    "    \n",
    "    # change column type and name\n",
    "    df_cleaned = df_cleaned.withColumn('Amount', F.regexp_replace('Amount', '[$,]', '').cast(IntegerType())) \\\n",
    "            .withColumnRenamed('Amount', 'Revenue')\n",
    "    \n",
    "    # remove negative value\n",
    "    df_cleaned = df_cleaned.filter((df_cleaned.Revenue != 0) & (df_cleaned.Boxes_Shipped != 0))\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(df_cleaned: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Add necessary columns to cleaned dataframe.\n",
    "\n",
    "    Parameter:\n",
    "        df_cleaned: Cleaned dataframe.\n",
    "\n",
    "    Return:\n",
    "        Dataframe with necessary columns added.\n",
    "    \"\"\"\n",
    "\n",
    "    # add first name and last name columns\n",
    "    df_added = df_cleaned.withColumn('First_Name', F.split('Sales_Person', ' ')[0]) \\\n",
    "            .withColumn('Last_Name', F.split('Sales_Person', ' ')[1])\n",
    "    \n",
    "    # calculate revenue per box column\n",
    "    df_added = df_added.withColumn('Revenue_Per_Box', F.round(df_added['Revenue'] / df_added['Boxes_Shipped'], 2).cast(DecimalType(10, 2)))\n",
    "\n",
    "    # extract date components\n",
    "    df_added = df_added.withColumn('Date_Key', F.date_format('Date', 'yyyyMMdd')) \\\n",
    "                        .withColumn('Year', F.year('Date')) \\\n",
    "                        .withColumn('Quarter', F.quarter('Date')) \\\n",
    "                        .withColumn('Month', F.month('Date')) \\\n",
    "                        .withColumn('Day', F.dayofmonth('Date')) \\\n",
    "                        .withColumn('Start_Of_Year', F.trunc('Date', 'year')) \\\n",
    "                        .withColumn('Start_Of_Quarter', F.trunc('Date', 'quarter')) \\\n",
    "                        .withColumn('Start_Of_Month', F.trunc('Date', 'month'))\n",
    "    \n",
    "    return df_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(df: DataFrame, silver_storage_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save output dataframe to silver layer.\n",
    "\n",
    "    Parameter:\n",
    "        df: Target dataframe.\n",
    "        silver_storage_path: Path to silver layer storage.\n",
    "\n",
    "    Return:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    df.write \\\n",
    "        .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "        .save(silver_storage_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0362fdac",
   "metadata": {},
   "source": [
    "# Define main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00699a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function to transform data from bronze layer.\n",
    "\n",
    "    Parameter:\n",
    "        None.\n",
    "\n",
    "    Return:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        logging.info('Start transforming data.')\n",
    "\n",
    "        # read data from bronze\n",
    "        df_bronze = read_data(spark, 'parquet', bronze_schema, bronze_file_path)\n",
    "\n",
    "        # clean data\n",
    "        df_cleaned = clean_data(df_bronze)\n",
    "\n",
    "        # add columns\n",
    "        df_added = add_columns(df_cleaned)\n",
    "\n",
    "        # data quality checks\n",
    "        data_quality_checks(dq_engine, checks_file_path, df_added)\n",
    "\n",
    "        # write data to silver\n",
    "        write_data(df_added, silver_storage_path)\n",
    "\n",
    "        logging.info('Wrote data to silver layer.')\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error occured: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52dca0",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bef036",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
