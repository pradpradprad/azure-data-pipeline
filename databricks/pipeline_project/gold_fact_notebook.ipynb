{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49956b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructField, StructType, IntegerType,\n",
    "    StringType, DateType, DecimalType\n",
    ")\n",
    "\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb11a3",
   "metadata": {},
   "source": [
    "# Setting log level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92091aa6",
   "metadata": {},
   "source": [
    "# Create parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.text('storage_account', '0')\n",
    "dbutils.widgets.text('year', '0')\n",
    "dbutils.widgets.text('month', '0')\n",
    "dbutils.widgets.text('day', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account = dbutils.widgets.get('storage_account')\n",
    "year = dbutils.widgets.get('year')\n",
    "month = dbutils.widgets.get('month')\n",
    "day = dbutils.widgets.get('day')\n",
    "\n",
    "silver_file_path = f'abfss://silver@{storage_account}.dfs.core.windows.net/transformed_data/{year}/{month}/{day}/'\n",
    "\n",
    "# create data quality instance connected to databricks workspace\n",
    "dq_engine = DQEngine(WorkspaceClient())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49dadb",
   "metadata": {},
   "source": [
    "# Define schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_schema = StructType([\n",
    "    StructField('Sales_Person_ID', IntegerType(), False),\n",
    "    StructField('Sales_Person', StringType(), False),\n",
    "    StructField('Country', StringType(), False),\n",
    "    StructField('Product_ID', IntegerType(), False),\n",
    "    StructField('Product', StringType(), False),\n",
    "    StructField('Date', DateType(), False),\n",
    "    StructField('Revenue', IntegerType(), False),\n",
    "    StructField('Boxes_Shipped', IntegerType(), False),\n",
    "    StructField('First_Name', StringType(), False),\n",
    "    StructField('Last_Name', StringType(), False),\n",
    "    StructField('Revenue_Per_Box', DecimalType(10, 2), False),\n",
    "    StructField('Date_Key', StringType(), False),\n",
    "    StructField('Year', IntegerType(), False),\n",
    "    StructField('Quarter', IntegerType(), False),\n",
    "    StructField('Month', IntegerType(), False),\n",
    "    StructField('Day', IntegerType(), False),\n",
    "    StructField('Start_Of_Year', DateType(), False),\n",
    "    StructField('Start_Of_Quarter', DateType(), False),\n",
    "    StructField('Start_Of_Month', DateType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657ccc7",
   "metadata": {},
   "source": [
    "# Run common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./utils/common_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dcc75a",
   "metadata": {},
   "source": [
    "# Define extra check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_composite_key(df: DataFrame, col: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Check for duplicates in composite key columns, raise error if check failed.\n",
    "\n",
    "    Parameter:\n",
    "        df: Dataframe to check data quality.\n",
    "        col: List of composite key columns to count duplicates.\n",
    "\n",
    "    Return:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    composite_duplicate_count = df.groupBy(col).count().filter(F.col('count') > 1).count()\n",
    "\n",
    "    assert composite_duplicate_count == 0, f'{composite_duplicate_count} composite duplicates found in the data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6403bd",
   "metadata": {},
   "source": [
    "# Define main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function to create fact table.\n",
    "\n",
    "    Parameter:\n",
    "        None.\n",
    "\n",
    "    Return:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # define variables\n",
    "    fact_table_name = 'sales_catalog.gold.fact_sales'\n",
    "    checks_file_path = '/pipeline_project/check/checks_gold_fact_sales.yml'\n",
    "    merge_condition = '''\n",
    "        trg.Sales_Person_Key = src.Sales_Person_Key\n",
    "        AND trg.Product_Key = src.Product_Key\n",
    "        AND trg.Country_Key = src.Country_Key\n",
    "        AND trg.Date_Key = src.Date_Key\n",
    "    '''\n",
    "    gold_storage_path = f'abfss://gold@{storage_account}.dfs.core.windows.net/fact_sales'\n",
    "\n",
    "    try:\n",
    "        logging.info('Creating fact sales.')\n",
    "\n",
    "        # read data from silver layer\n",
    "        df_silver = read_data(spark, 'parquet', silver_schema, silver_file_path)\n",
    "\n",
    "        # read data from dimension tables\n",
    "        df_dim_sales_person = spark.read.table('sales_catalog.gold.dim_sales_person')\n",
    "        df_dim_product = spark.read.table('sales_catalog.gold.dim_product')\n",
    "        df_dim_country = spark.read.table('sales_catalog.gold.dim_country')\n",
    "        df_dim_date = spark.read.table('sales_catalog.gold.dim_date')\n",
    "\n",
    "        # select necessary columns\n",
    "        df_total = df_silver.join(df_dim_sales_person, on='Sales_Person_ID', how='left') \\\n",
    "                            .join(df_dim_product, on='Product_ID', how='left') \\\n",
    "                            .join(df_dim_country, on='Country', how='left') \\\n",
    "                            .join(df_dim_date, on='Date_Key', how='left') \\\n",
    "                            .select(\n",
    "                                df_dim_sales_person['Sales_Person_Key'],\n",
    "                                df_dim_product['Product_Key'],\n",
    "                                df_dim_country['Country_Key'],\n",
    "                                df_dim_date['Date_Key'],\n",
    "                                df_silver['Revenue'],\n",
    "                                df_silver['Boxes_Shipped'],\n",
    "                                df_silver['Revenue_Per_Box']\n",
    "                            )\n",
    "        \n",
    "        # data quality checks\n",
    "        data_quality_checks(dq_engine, checks_file_path, df_total)\n",
    "\n",
    "        # composite key check\n",
    "        check_composite_key(df_total, ['Sales_Person_Key', 'Product_Key', 'Country_Key', 'Date_Key'])\n",
    "\n",
    "        # merge data\n",
    "        merge_data(spark, fact_table_name, df_total, merge_condition, gold_storage_path)\n",
    "\n",
    "        logging.info('Finished creating fact table.')\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error occured: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e723be",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
